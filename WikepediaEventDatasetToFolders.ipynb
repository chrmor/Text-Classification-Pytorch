{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this outputs the dataset as folders of text files, each folder corresponds to a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "from random import shuffle\n",
    "\n",
    "def toFolders(source_field, start, end, minConf, min_text_len, dir_in, suffix, dir_out, instances_per_class):\n",
    "    \n",
    "    idx = 0;\n",
    "    \n",
    "    listEvents = []\n",
    "    for year in range(start,end+1):\n",
    "        filename='wiki-events-' + str(year) + suffix + '.json.gz'\n",
    "        print(\"loading file \" + filename + \" ...\")\n",
    "        with gzip.open(os.path.join(dir_in, filename), \"rb\") as f:\n",
    "            events = json.loads(f.read().decode(\"utf8\"))\n",
    "        print(\"found \" + str(len(events['results'])) + \" events...\")\n",
    "        listEvents = listEvents + events['results']\n",
    "        print(\"total: \" + str(len(listEvents)) + \" events...\")\n",
    "\n",
    "    classes = {'armed conflicts and attacks':'armed conflicts and attacks', \n",
    "               'politics and elections':'politics and elections', \n",
    "               'law and crime':'law and crime', 'disasters and accidents':'disasters and accidents', \n",
    "               #'international relations':'international relations', \n",
    "               'sport':'sport', 'business and economy':'business and economy', \n",
    "               'arts and culture':'arts and culture', 'science and technology':'science and technology',\n",
    "               'science': 'science and technology', \n",
    "               #'health and medicine': 'health and medicine',\n",
    "               #'health and environmnet': 'health and medicine',\n",
    "              }\n",
    "    classInstances = {}\n",
    "\n",
    "    shuffle(listEvents)\n",
    "    \n",
    "    for event in listEvents:\n",
    "        #check is the keys are present\n",
    "        if 'event-type' in event and 'full-text' in event:\n",
    "            #keep only events with non empty full-text and event-type\n",
    "            if event['full-text'] and event['event-type'] and len(event['full-text'])>min_text_len:\n",
    "                label = event['event-type']\n",
    "                if (label in classes):\n",
    "                    entities = event['entities']\n",
    "                    if source_field=='entities':\n",
    "                        text = ''\n",
    "                        for entity in entities:\n",
    "                            avgconf = sum(float(i) for i in entity['confidence'])/len(entity['confidence'])\n",
    "                            if avgconf > minConf:\n",
    "                                text = text + ' ' + entity['label']\n",
    "                    elif source_field=='short-text':\n",
    "                        text = event['event']\n",
    "                    elif source_field=='full-text':\n",
    "                        text = event['full-text']\n",
    "                    elif source_field=='entity-categories':\n",
    "                        text = ''\n",
    "                        for entity in entities:\n",
    "                            avgconf = sum(float(i) for i in entity['confidence'])/len(entity['confidence'])\n",
    "                            if avgconf > minConf:\n",
    "                                text = text + ' ' + \" \".join(entity['categories']).replace(\"_\",\" \")\n",
    "                                    \n",
    "                    if (not classes[label] in classInstances):\n",
    "                        classInstances[classes[label]] = []\n",
    "                    \n",
    "                    if (len(classInstances[classes[label]]) >= instances_per_class):\n",
    "                        continue\n",
    "                        \n",
    "                    classInstances[classes[label]].append(text)\n",
    "                    \n",
    "\n",
    "    print(\"Selected total events: \" + str(idx))\n",
    "    train_n = 0;\n",
    "    test_n = 0;\n",
    "    for cls in classInstances:\n",
    "        insts = classInstances[cls]\n",
    "        test_index = int(len(insts)*0.8)\n",
    "        train = insts[:test_index]\n",
    "        test = insts[test_index:]\n",
    "        print(cls, len(insts))\n",
    "    \n",
    "        idx = 0;\n",
    "        for text_tr in train:\n",
    "            out_path = os.path.join(dir_out + \"/train\", cls)\n",
    "            if not os.path.exists(out_path):\n",
    "                os.makedirs(out_path)\n",
    "            with open(os.path.join(out_path, str(idx)), 'a') as the_file:\n",
    "                the_file.write(text_tr)   \n",
    "            idx += 1\n",
    "            train_n += 1\n",
    "        print(\"train: \" + str(idx))\n",
    "        idx = 0\n",
    "        for text_tr in test:\n",
    "            out_path = os.path.join(dir_out + \"/test\", cls)\n",
    "            if not os.path.exists(out_path):\n",
    "                os.makedirs(out_path)\n",
    "            with open(os.path.join(out_path, str(idx)), 'a') as the_file:\n",
    "                the_file.write(text_tr)\n",
    "            idx += 1\n",
    "            test_n += 1\n",
    "        print(\"test: \" + str(idx))\n",
    "    print(\"total train: \" + str(train_n))\n",
    "    print(\"total test: \" + str(test_n))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file wiki-events-2010_multilink_data_clean.json.gz ...\n",
      "found 12888 events...\n",
      "total: 12888 events...\n",
      "loading file wiki-events-2011_multilink_data_clean.json.gz ...\n",
      "found 8997 events...\n",
      "total: 21885 events...\n",
      "loading file wiki-events-2012_multilink_data_clean.json.gz ...\n",
      "found 6513 events...\n",
      "total: 28398 events...\n",
      "loading file wiki-events-2013_multilink_data_clean.json.gz ...\n",
      "found 5858 events...\n",
      "total: 34256 events...\n",
      "loading file wiki-events-2014_multilink_data_clean.json.gz ...\n",
      "found 3698 events...\n",
      "total: 37954 events...\n",
      "loading file wiki-events-2015_multilink_data_clean.json.gz ...\n",
      "found 5921 events...\n",
      "total: 43875 events...\n",
      "loading file wiki-events-2016_multilink_data_clean.json.gz ...\n",
      "found 6186 events...\n",
      "total: 50061 events...\n",
      "loading file wiki-events-2017_multilink_data_clean.json.gz ...\n",
      "found 3212 events...\n",
      "total: 53273 events...\n",
      "Selected total events: 0\n",
      "sport 2349\n",
      "train: 1879\n",
      "test: 470\n",
      "politics and elections 5727\n",
      "train: 4581\n",
      "test: 1146\n",
      "law and crime 5068\n",
      "train: 4054\n",
      "test: 1014\n",
      "armed conflicts and attacks 8784\n",
      "train: 7027\n",
      "test: 1757\n",
      "international relations 3579\n",
      "train: 2863\n",
      "test: 716\n",
      "disasters and accidents 4752\n",
      "train: 3801\n",
      "test: 951\n",
      "science and technology 1207\n",
      "train: 965\n",
      "test: 242\n",
      "health and medicine 412\n",
      "train: 329\n",
      "test: 83\n",
      "business and economy 2343\n",
      "train: 1874\n",
      "test: 469\n",
      "arts and culture 1806\n",
      "train: 1444\n",
      "test: 362\n",
      "total train: 28817\n",
      "total test: 7210\n",
      "CPU times: user 1min 46s, sys: 27.3 s, total: 2min 13s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "years_range = [2010,2017]\n",
    "source_field = \"full-text\" #'entity-categories'\n",
    "min_text_len = 50\n",
    "instances_per_class = 10000 #1207\n",
    "data_dir='../events-allignement/data/wikipedia-events-portal/clean/json'\n",
    "#dir_out= 'Text_Classifier/.data/WE_clean_balanced_' + str(instances_per_class) + '/' + str(years_range[0]) + '-' + str(years_range[1]) + '-' + source_field\n",
    "dir_out= 'Text_Classifier/.data/WE_clean_10/' + str(years_range[0]) + '-' + str(years_range[1]) + '-' + source_field\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "%time toFolders(source_field,years_range[0],years_range[1],0.6, 50, data_dir, \"_multilink_data_clean\", dir_out, instances_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
